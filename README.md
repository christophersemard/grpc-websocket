

# üêü Aquarium

Une application permettant d'afficher en temps r√©√©l des poissons se d√©pla√ßant dans un aquarium et accessoirement de comparer le performances entre la communication WebSocket et gRPC.

---

## ‚öôÔ∏è Pr√©requis

- **Docker + Docker Compose**

---

## üöÄ Lancer le projet avec Docker

1. Cloner le projet

```bash
git clone https://github.com/christophersemard/aquarium.git
cd grpc-websocket
```

2. D√©marrer tous les services

```bash
docker-compose up --build
```

3. Acc√©der √† l'application sur

```
http://localhost:3000 
```
pour la page d'accueil avec la modification de poisson et d'intervalle

```
http://localhost:3000/benchmark 
```
pour la page de benchmark automatique

---
## üß† Technologies utilis√©es

| Composant | Stack | R√¥le |
|:----------|:------|:-----|
| Frontend | **Next.js 15**, **TypeScript**, **TailwindCSS**, **SSE**, **gRPC**, **WebSocket** | Il re√ßoit les donn√©es du serveur en WebSocket ou en SSE (via gRPC). Il affiche les poissons en temps r√©el et collecte les m√©triques de latence. |
| Serveur | **Node.js**, **gRPC**, **WebSocket**, **TypeScript** | Il g√©n√®re les positions des poissons en continu et diffuse les mises √† jour en temps r√©el aux clients √† la fois via WebSocket et via gRPC. |
| Proto | **Fichier `.proto`** | Le fichier `.proto` d√©finit les contrats d'interface gRPC pour l'envoi des `FishBatch` et la mise √† jour dynamique de la configuration (nombre de poissons, intervalle d'envoi). |

---

## üìÇ Structure du projet

```bash
.
‚îú‚îÄ‚îÄ anciens-benchmarks/                     # Scripts de benchmark (WebSocket & gRPC)
‚îÇ
‚îú‚îÄ‚îÄ fish-frontend/                          # Interface utilisateur (Next.js)
‚îÇ   ‚îú‚îÄ‚îÄ src/app/api/grpc/route.ts           # Route API SSE r√©cup√©rant les donn√©es du serveur en gRPC
‚îÇ   ‚îú‚îÄ‚îÄ src/hooks/useFishGrpc.ts            # Hook pour recevoir les poissons en temps r√©el via gRPC (SSE)
‚îÇ   ‚îú‚îÄ‚îÄ src/hooks/useFishWebSocket.ts       # Hook pour recevoir les poissons en temps r√©el via WebSocket
‚îÇ   ‚îú‚îÄ‚îÄ src/components/                     # Composants UI (Aquarium, MetricsPanel, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ src/app/page.tsx                    # Page principale de l'application
‚îÇ   ‚îî‚îÄ‚îÄ proto/fish.proto                    # Fichier gRPC proto (copie pour le frontend)
‚îÇ
‚îú‚îÄ‚îÄ fish-server/                            # G√©n√®re et diffuse les poissons (gRPC & WebSocket)
‚îÇ   ‚îú‚îÄ‚îÄ index.ts                            # Serveur principal
‚îÇ   ‚îî‚îÄ‚îÄ proto/fish.proto                    # Fichier gRPC proto (r√©f√©rence serveur)
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml                      # Compose pour orchestrer le serveur et le frontend
‚îÇ
‚îî‚îÄ‚îÄ README.md                               # Documentation du projet
```


---

## üì° Objectif du projet

On veut analyser, √† notre niveau, l'utilisation de deux technologies afin d'envoyer des donn√©es en temps r√©√©l. Pour cela on va comparer le gRPC (+ SSE pour l'envoi au client) et le WebSocket.

### Ce qu‚Äôon veut observer ici :

- **La latence** : combien de temps s‚Äô√©coule entre l‚Äôenvoi et la r√©ception d‚Äôune donn√©e ?
- **Le d√©bit** : est-ce que des messages se perdent, √† quelle vitesse peut-on recevoir les data ?
- **Le capacit√© de charge** : est-ce que √ßa crash ? Est-ce que les connexions tiennent ?

---

## Benchmarks effectu√©s

Pour mieux comprendre les **performances** et les **latences** de chaque m√©thode (WebSocket et gRPC), j‚Äôai mis en place un syst√®me de **tests automatis√©s** dans le dossier `benchmarks`.

Ces tests ne passent **pas du tout par le frontend**. Ils se connectent **directement au serveur**, pour mesurer uniquement ce qui se passe c√¥t√© r√©seau et traitement ‚Äî sans que l‚Äôinterface utilisateur ou le navigateur influence les r√©sultats. 

J'ai fait comme ceci les benchmarks, et non directement dans l'application frontend, car dans le cas d'utilisation du gRPC pour un affichage en frontend via un navigateur, on est toujours oblig√© d'avoir un serveur qui r√©cup√®re la data puis la renvoie en SSE ou WebSocket vers notre navigateur. **On ne peut pas faire de gRPC natif via notre navigateur** ce qui est une grosse limite de ce protocole pour l'applicatif web.

### Objectif

Le but des ces tests est de conna√Ætre :

- La **latence moyenne** (temps entre l‚Äôenvoi et la r√©ception d‚Äôun message).
- La **m√©diane**, les **percentiles 10/90** pour mieux comprendre la distribution des latences.
- L'**√©cart-type** pour mesurer la stabilit√©.
- Le **nombre de poissons actifs** pour v√©rifier la robustesse.
- La comparaison entre **WebSocket** et **gRPC** dans des conditions √©quivalentes.

### M√©thodologie

Pour tester notre applicatif et les diff√©rences entre les deux protocoles, j'ai d√©cid√© de cr√©er un benchmark directement en frontend.

- Chaque sc√©nario ajuste dynamiquement le **nombre de poissons** et la **fr√©quence d'envoi** via une API (`/api/config`).
- Avant de commencer les mesures, le benchmark **attend** que le nombre de poissons soit stabilis√©.
- Ensuite, il **collecte les donn√©es** sur **WebSocket** et **gRPC** en parall√®le.
- Les r√©sultats sont **sauvegard√©s** et affich√©s dans un tableau de comparaison final.


## Limites

Durant ces tests je me suis heurt√© √† plusieurs limites, notamment sur l'applicatif, cot√© frontend notamment o√π l'affichage des poissons ralentissait beaucoup l'application, chose que j'ai r√©ussi √† limiter en utilisant un canvas html.

On ne mesure pas l'effet de plusieurs clients connect√©s dans ce benchmark.

Note importante :
- En WebSocket, la connexion est directe entre frontend et serveur.
- En gRPC, le frontend utilise une **route API** qui √©tablit une connexion gRPC serveur ‚Üí frontend via **SSE**. Cela peut introduire une l√©g√®re latence suppl√©mentaire **propre au navigateur**.

On ne mesure pas l'usage CPU ou m√©moire du serveur pendant les tests.

## R√©sultats du benchmark

| Sc√©nario | Protocole | Moyenne | M√©diane | P10 | P90 | √âcart-type | Min | Max |
|:---|:---|---:|---:|---:|---:|---:|---:|---:|
| 100 poissons / 100ms | <span style="color:#3b82f6;font-weight:bold;">WebSocket</span> | <span style="color:green;">1 ms</span> | 1 ms | 1 ms | 2 ms | 0 ms | 1 ms | 2 ms |
| | <span style="color:#10b981;font-weight:bold;">gRPC</span> | <span style="color:green;">2 ms</span> | 2 ms | 1 ms | 2 ms | 2 ms | 1 ms | 9 ms |
| 200 poissons / 50ms | <span style="color:#3b82f6;font-weight:bold;">WebSocket</span> | <span style="color:green;">1 ms</span> | 1 ms | 1 ms | 2 ms | 1 ms | 1 ms | 4 ms |
| | <span style="color:#10b981;font-weight:bold;">gRPC</span> | <span style="color:green;">3 ms</span> | 2 ms | 1 ms | 5 ms | 2 ms | 1 ms | 11 ms |
| 500 poissons / 30ms | <span style="color:#3b82f6;font-weight:bold;">WebSocket</span> | <span style="color:green;">4 ms</span> | 2 ms | 1 ms | 9 ms | 3 ms | 1 ms | 12 ms |
| | <span style="color:#10b981;font-weight:bold;">gRPC</span> | <span style="color:green;">6 ms</span> | 5 ms | 3 ms | 11 ms | 3 ms | 3 ms | 17 ms |
| 1000 poissons / 20ms | <span style="color:#3b82f6;font-weight:bold;">WebSocket</span> | <span style="color:orange;">84 ms</span> | 81 ms | 67 ms | 104 ms | 16 ms | 21 ms | 108 ms |
| | <span style="color:#10b981;font-weight:bold;">gRPC</span> | <span style="color:green;">18 ms</span> | 17 ms | 10 ms | 28 ms | 7 ms | 5 ms | 35 ms |
| 2500 poissons / 20ms | <span style="color:#3b82f6;font-weight:bold;">WebSocket</span> | <span style="color:orange;">429 ms</span> | 102 ms | 71 ms | 1680 ms | 692 ms | 52 ms | 1857 ms |
| | <span style="color:#10b981;font-weight:bold;">gRPC</span> | <span style="color:green;">36 ms</span> | 35 ms | 15 ms | 55 ms | 16 ms | 10 ms | 79 ms |
| 4000 poissons / 20ms | <span style="color:#3b82f6;font-weight:bold;">WebSocket</span> | <span style="color:red;">8752 ms</span> | 8736 ms | 8516 ms | 9038 ms | 190 ms | 8403 ms | 8790 ms |
| | <span style="color:#10b981;font-weight:bold;">gRPC</span> | <span style="color:green;">23 ms</span> | 21 ms | 17 ms | 31 ms | 7 ms | 13 ms | 35 ms |
| 5000 poissons / 20ms | <span style="color:#3b82f6;font-weight:bold;">WebSocket</span> | <span style="color:red;">21388 ms</span> | 20478 ms | 20372 ms | 24824 ms | 1929 ms | 20343 ms | 26495 ms |
| | <span style="color:#10b981;font-weight:bold;">gRPC</span> | <span style="color:orange;">99 ms</span> | 100 ms | 64 ms | 135 ms | 26 ms | 52 ms | 158 ms |

## Ancien syst√®me de benchmark

Avant de passer au benchmark en frontend directement connect√©, j'avais mis en place un **syst√®me de benchmark s√©par√©** dans le dossier `anciens-benchmarks/`.

Ce syst√®me :
- Se connectait **directement** au serveur via WebSocket ou gRPC.
- Simulait un ou plusieurs clients pour mesurer :
  - La latence moyenne,
  - Le nombre de messages re√ßus,
  - Le taux de perte de messages,
  - Le comportement sous charge.

Cependant, ce benchmark avait plusieurs **limitations** :
- **Pas de prise en compte** de l'affichage frontend (qui impacte les performances en r√©alit√©).
- **Pas repr√©sentatif** de l'exp√©rience utilisateur r√©elle dans un navigateur.
- **Ouverture d'un flux grpc pour chaque client**, ce qui n'est pas le cas en frontend puisque la partie serveur cr√©e un seul flux puis l'envoie √† tous les clients.


# Analyse des r√©sultats

Les r√©sultats montrent clairement que les deux protocoles fonctionnent tr√®s bien tant qu'on reste en dessous de **500 poissons**. La latence reste tr√®s basse (entre **1 et 11 ms**), et **stable**.  √Ä ce niveau et cette charge, les deux protocoles semblent **assez identiques**.

Mais d√®s qu'on monte au-dessus de **500 poissons** on voit que le **WebSocket devient beaucoup plus lent**, beaucoup **moins stable**, et √† partir de **2500 poissons** il n'est carr√©ment **plus comparable** au **gRPC** qui reste **tr√®s stable**.

On voit donc que si on compare les deux protocoles avec **un seul client** pour chaque, **il n'y a pas photo** entre le WebSocket et le gRPC, le dernier √©tant bien plus efficace.

---

Mes anciens benchmarks avec plusieurs clients connect√©s m'ont quand m√™me fait observer des choses int√©ressantes √©galement :

- Avec **gRPC**, **tous les clients arrivent √† se connecter** et **re√ßoivent leurs messages**. Mais la **latence augmente**, jusqu‚Äô√† **plusieurs secondes** pour certains clients. Le souci est qu'ouvrir un flux gRPC par client demande des infrastructures bien plus complexes et efficaces, ce n'est pas viable d'ouvrir 500 flux gRPC sur un petit serveur Node.

- Avec **WebSocket**, un autre probl√®me appara√Æt, certaines **connexions sont carr√©ment refus√©es**. Cependant c'est beaucoup moins lourd d'ouvrir une connexion WebSocket qu'un nouveau flux gRPC.

---

D√®s qu‚Äôon pousse trop loin, on atteint les **limites de mon impl√©mentation actuelle**,  on peut quand m√™me penser que **gRPC est un peu plus fiable et plus robuste** et supporte mieux une charge lourde sur un seul client, mais pour connecter beaucoup de clients il faudrait une impl√©mentation bien plus optimis√©e.


# Avantages et inconv√©nients

### WebSocket

**‚úÖ Avantages :**
- Fonctionne **directement dans les navigateurs**, sans passerelle suppl√©mentaire en NodeJS
- **Simple √† mettre en place** pour les d√©veloppeurs peeu exp√©riment√©s
- Suffisant dans la **majorit√© des cas d'usage** si la charge est mod√©r√©e.

**‚ùå Inconv√©nients :**
- **Moins typ√©** et structur√© que gRPC (messages en JSON par d√©faut).
- Semble montrer ses **limites sur des charges lourdes**.
- **Facilit√© de lire les donn√©es intercept√©es** si on envoie des JSON.
- **Limites sur la stabilit√©** des connexion (refus de connexion notamment sur mes benchmarks)

**üí° Cas d‚Äôusage :**
- Interfaces **web en temps r√©el**
- Applications webs o√π **le navigateur doit recevoir des infos sans trop de d√©lai**
- Projets simples √† moyens o√π **l‚Äô√©chelle est contr√¥l√©e**

---

### gRPC

**‚úÖ Avantages :**
- Tr√®s **rapide et optimis√©**, surtout pour les communications **serveur √† serveur**.
- Messages **fortement typ√©s**, bien d√©finis via des fichiers `.proto`, le contrat d'interface permet de ne pas pouvoir se tromper (en th√©orie).
- Semble avoir de meilleures performances √† grande √©chelle.

**‚ùå Inconv√©nients :**
- **Pas utilisable directement dans les navigateurs** avec NodeJS, n√©cesite un serveur ou un proxy qui r√©cup√®re les donn√©es avant de les envoyer au client autrement (SSE ou WebSocket). Ajoute une **latence suppl√©mentaire** √† cause de cette passerelle.
- Mise en place et debug **plus complexes** qu‚Äôun WebSocket simple au d√©part.
- **Plus compliqu√© pour l'applicatif d'ouvrir beaucoup de flux gRPC** que beaucoup de flux Websocket

**üí° Cas d‚Äôusage :**
- **Communication entre microservices**, c'est ce que j'utilise dans mon projet de fin d'ann√©e avec une Gateway expos√©e en HTTP et mes microservices derri√®re qui communiquent en gRPC avec la Gateway.
- **Applications critiques** o√π la **performance serveur** est prioritaire (ex: banque, industrie).
- Sc√©narios avec **beaucoup de clients connect√©s en m√™me temps**.
- Exemple concret : dans notre projet Twitch de cours, on avait constat√© que **gRPC √©tait beaucoup plus robuste pour transmettre l‚Äô√©tat du stream**, mais **pas id√©al pour envoyer de la vid√©o**, d'autres protocoles sont faits pour √ßa (RTC)

---

## Am√©liorations possibles de notre application

- D√©ploiement sur **VPS** pour tester dans des conditions plus r√©alistes sur le r√©seau.
- Mise en place de plusieurs serveurs.
- **S√©paration des serveurs** WebSocket et gRPC dans des processus ou containers distincts pour √©viter qu'ils ne se p√©nalisent mutuellement.
- Ajout d‚Äôun **monitoring** (ex : Grafana) pour connaitre l'utilisation de ressources de l'application.
- **Tests avec charge r√©seau simul√©e** (latence artificielle, pertes de paquets) pour √©valuer la robustesse de chaque protocole dans des conditions d√©grad√©es comme on avait vu en cours avec les logiciels de chaos engineering
- **Optimiser les donn√©es** et leur type envoy√©es

---

## Conclusion

Aucune technologie n‚Äôest "meilleure" dans l‚Äôabsolu, tout d√©pend **du contexte** et **des contraintes du projet**.

- Si on vise un **affichage temps r√©el dans un navigateur**, avec peu de clients, **WebSocket est id√©al** car simple √† mettre en place.
- Pour **des syst√®mes distribu√©s**, **des infrastructures √† forte charge**, ou **des communications entre serveurs**, **gRPC offre une robustesse, une fiabilit√© et une scalabilit√© sup√©rieures**.

Ce projet permet de tester les **forces et limites r√©elles** de ces technos, et surtout, de comprendre **√† quel moment il faut utiliser l‚Äôune ou l‚Äôautre**.

**En r√©sum√© :**  
- **WebSocket** brille par sa **simplicit√©** pour le **temps r√©el l√©ger** c√¥t√© navigateur.  
- **gRPC** par sa **rigueur** et sa **r√©silience** dans des architectures **plus exigeantes**.
